# üìã StoryWeave Chronicles ‚Äì Project TODO List (September 17, 2025)

## ‚úÖ Completed & Stable
- Newsletter feature added
- Export/import bookmarks implemented
- Carousel mobile issues fixed (desktop/mobile both usable, needs polish)
- Database migrated to Neon (persistent, fast cover loading)
- Cover caching system optimized and stress tested
- RAM usage optimized (open to further improvements)
- Made a new cover system for the sake of being super optimized. (way faster and using way less memory if you can get over the first dry launch)
- managed to finally clean up and organize my back end. (will do the same for the front end once its completely stable)
- finally i can consider covers done on render. the download and everything works like a dream. i think it can handle 100 users no problem.
- fixed infinite polling with yet ANOTHER cover system. but this one is not only working, but is the most stable and the most optimized.
- FINALLY fixed the routing issue. no more!

---

## ‚òê Remaining Bugs & Improvements
- Carousel UI: polish for desktop and mobile
- for advertising: propellerads, adsterra, and revenuehits are the ones i want to look at the most.
- moving the schedules and mail to google cloud (and having uploads/updates automatically send out notifications and update the database)
- churn is back. it fixed itself for a bit and now its back. (doesn't do TOO much damage, but still anoying)

---

## üöÄ Future Goals
- Continue monitoring and optimizing RAM/CPU usage
- Add admin tools: logs, rate limiting, restore deleted content, user activity overview
- Set up automated alerts for memory, queue length, error rates
- Consider service workers for offline access
- General UI polish and performance enhancements
- Username changes (stretch goal, not prioritized)
- cleanup and organize front end

---
## Deployment Constraints

- **Render Free Tier:**  
  - 256 MB RAM, 0.1 CPU, 100 connections per instance.
  - 750 free instance hours/month.
  - Services spin down after 15 minutes inactivity.
  - PostgreSQL: 1GB, expires every 30 days (moved to neon, no need to worry about this).
---

**Summary:**
Most major features and optimizations are complete. Focus now shifts to bug fixes, UI polish, admin tools, and ongoing performance improvements. Let me know which item you want to tackle next!

---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

for definition so that we are on the same page: i am defining churn as = if the site deletes needed covers and then redownloads them wasting resources and time.
so with my react site, i have an atlas and a folder full of covers. the image name is the <cover id>.jpg. for some reason, it will do a comparison on the landing page list
remove covers that are in the folder believing it doesn't need them, realizes it DOES need those covers, and will redownload them. that is a churn to me.
if it were to delete, redownload, delete, redownload, that is 2 churns.

with definitions out of the way, i have had a churn problem every time i refresh the landing page. i can get all covers up and running perfectly. if i refresh to test,
the site for some reason deletes 10 covers saying they are not valid cause they dont exist. it then redownloads new versions. this is using up resources i can be putting
towards something else. remember i am deployed on render.com free tier. that doesn't give me a lot of resources to work with. so i need to make things as efficient and 
optimized as possible. which is why i want this churn gone!

(for memories sake:
- **Render Free Tier:**  
  - 256 MB RAM, 0.1 CPU, 100 connections per instance.
  - 750 free instance hours/month.
  - Services spin down after 15 minutes inactivity.
  - PostgreSQL: 1GB, expires every 30 days.)

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
no thanks just wanted to get you caught up to speed. so i just spent time cleaning up the backend and making it compatable with flask-restx so i can have my won openapi page. i did this because im setting up my CI/CD with help from github actions. the new setup im trying to have is local testing (what we are doing now) then a dev branch that goes live on render where i can test things in a live environment without worry. and then a production branch on github and render that users actually use. that way i can test and make new features. and if i break something the site isnt down for all users. i created another site specifically for dev on render. made a new branch called dev and connected it with render. made new branch rules so that you HAVE to pull request and pull requests HAVE to be approved to push changes from dev to prod. i also wanted to set up environments that dev has to pass before github will even let you make a pull request. one of those was a node tester (honestly thats how i found out that my current set up is only compatable with node 20 and onwards.) and now i want a way to be able to check the api to make sure they are robust and secure before we throw whatever new endpoints we make into prod. i found a github action for mayhem api. I created a mayhem account and as you just saw, i have refactored my entire flask app to be compatable and make an openapi page that mayhem can test against for security purposes. thats where we are at right now. that is the current state of the site right now. 
---------------------------------------------------------------------------------------------------------------------------------------------------------------------
Your concerns are valid, and it's great that you're thinking about preserving critical functionality while improving the architecture. The good news is that we can absolutely retain the features you mentioned‚Äîsending notifications for updated books and adding metadata to the database‚Äîwhile transitioning to the new setup. Here's how we can address your concerns:

---

### **1. Retaining Notifications for Updated Books**
The `/api/seed-drive-books` endpoint currently sends notifications to users when a book in their bookmarks is updated. This functionality can be preserved by:
- **Extending the Google Drive Webhook**:
  - When the webhook detects an updated book, it can trigger the same logic that `/api/seed-drive-books` uses to send notifications.
  - This ensures that users are notified in real-time when a bookmarked book is updated.

---

### **2. Adding Metadata for New Books**
The `/api/seed-drive-books` endpoint also adds metadata for new books to the database. This can be handled by:
- **Processing New Book Events in the Webhook**:
  - When the webhook detects a new book, it can extract the metadata (e.g., title, file ID) and add it to the database.
  - This logic can be directly integrated into the webhook handler.

---

### **3. Updated Workflow**
Here‚Äôs how the new workflow would look:
1. **Google Drive Webhook**:
   - Detects new or updated books in the Drive folder.
   - For new books:
     - Extract metadata and add it to the database.
   - For updated books:
     - Check if the book is in any user‚Äôs bookmarks.
     - If yes, send notifications to those users.

2. **Database Updates**:
   - The webhook handler will directly interact with the database to add or update book metadata.

3. **Notifications**:
   - The webhook handler will use the existing notification logic to send updates to users.

---

### **4. Benefits of the New Setup**
- **Real-Time Updates**: Users are notified immediately when a bookmarked book is updated.
- **Simplified Architecture**: No need for a separate `/api/seed-drive-books` endpoint or scheduled jobs.
- **Cleaner Codebase**: All book-related updates are handled in one place (the webhook).

---

### **5. Implementation Plan**
Here‚Äôs how we can implement this:
1. **Extend the Webhook Handler**:
   - Add logic to process new and updated books.
   - For new books:
     - Extract metadata and add it to the database.
   - For updated books:
     - Check bookmarks and send notifications.

2. **Remove Redundant Code**:
   - Remove the `/api/seed-drive-books` endpoint.
   - Remove the `check_and_notify_new_books` scheduled job.

3. **Test the New Setup**:
   - Ensure that new books are added to the database correctly.
   - Verify that notifications are sent for updated books.

---

### **Next Steps**
Would you like me to start implementing these changes? If so, I can:
1. Update the Google Drive webhook handler to include the logic for adding metadata and sending notifications.
2. Remove the redundant `/api/seed-drive-books` endpoint and scheduled job.

Let me know how you‚Äôd like to proceed!
-----------------------------------------------------------------------------------------------------------------------------------------------------------------------
